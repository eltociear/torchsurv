
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>torchsurv.loss.weibull &#8212; torchsurv  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=384b581d" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/torchsurv/loss/weibull';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/logo_firecamp.png" class="logo__image only-light" alt="torchsurv  documentation - Home"/>
    <script>document.write(`<img src="../../../_static/logo_firecamp.png" class="logo__image only-dark" alt="torchsurv  documentation - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">API:</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../loss.html">Loss</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/torchsurv.loss.cox.html">torchsurv.loss.cox</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/torchsurv.loss.momentum.html">torchsurv.loss.momentum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/torchsurv.loss.weibull.html">torchsurv.loss.weibull</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../metrics.html">Metrics</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/torchsurv.metrics.auc.html">torchsurv.metrics.auc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/torchsurv.metrics.cindex.html">torchsurv.metrics.cindex</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/torchsurv.metrics.brier_score.html">torchsurv.metrics.brier_score</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../stats.html">Stats</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/torchsurv.stats.kaplan_meier.html">torchsurv.stats.kaplan_meier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/torchsurv.stats.ipcw.html">torchsurv.stats.ipcw</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials:</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/introduction.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/momentum.html">Survival with MNIST</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Other:</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../CHANGELOG.html">Change log</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../AUTHORS.html">Contributors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../devnotes.html">Development notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../benchmarks.html">Related packages</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1></h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for torchsurv.loss.weibull</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">sys</span>

<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">TORCH_CLAMP_VALUE</span> <span class="o">=</span> <span class="mf">1e10</span>


<div class="viewcode-block" id="neg_log_likelihood">
<a class="viewcode-back" href="../../../_autosummary/torchsurv.loss.weibull.html#torchsurv.loss.weibull.neg_log_likelihood">[docs]</a>
<span class="k">def</span> <span class="nf">neg_log_likelihood</span><span class="p">(</span>
    <span class="n">log_params</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">event</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">time</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">reduction</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
    <span class="n">checks</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Negative of the log likelihood for the Weibull Accelerated Time Failure (AFT) survival model.</span>

<span class="sd">    Args:</span>
<span class="sd">        log_params (torch.Tensor, float):</span>
<span class="sd">            Parameters of the Weibull distribution of shape = (n_samples, 1) or (n_samples, 2).</span>
<span class="sd">            The first column corresponds to the log scale parameter. The second column</span>
<span class="sd">            corresponds to the log shape parameter.  If the log shape parameter is missing, it is</span>
<span class="sd">            imputed with 0.</span>
<span class="sd">        event (torch.Tensor, bool):</span>
<span class="sd">            Event indicator of length n_samples (= True if event occured).</span>
<span class="sd">        time (torch.Tensor, float):</span>
<span class="sd">            Time-to-event or censoring of length n_samples.</span>
<span class="sd">        reduction (str):</span>
<span class="sd">            Method to reduce losses. Defaults to &quot;mean&quot;.</span>
<span class="sd">            Must be one of the following: &quot;sum&quot;, &quot;mean&quot;.</span>
<span class="sd">        checks (bool):</span>
<span class="sd">            Whether to perform input format checks.</span>
<span class="sd">            Enabling checks can help catch potential issues in the input data.</span>
<span class="sd">            Defaults to True.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (torch.Tensor, float): Negative of the log likelihood.</span>

<span class="sd">    Note:</span>

<span class="sd">        For each subject :math:`i \in \{1, \cdots, N\}`, denote :math:`X_i` as the survival time and :math:`D_i` as the</span>
<span class="sd">        censoring time. Survival data consist of the event indicator, :math:`\delta_i=1(X_i\leq D_i)`</span>
<span class="sd">        (argument ``event``) and the time-to-event or censoring, :math:`T_i = \min(\{ X_i,D_i \})`</span>
<span class="sd">        (argument ``time``).</span>

<span class="sd">        The log hazard function for the Weibull AFT survival model :cite:p:`Carroll2003` of subject :math:`i` at time :math:`t` has the form:</span>

<span class="sd">        .. math::</span>

<span class="sd">            \log h_i(t) = \log{\rho_i} - \log{\lambda_i} + (\rho_i -1) \left( \log{t} - \log{\lambda_i}\right)</span>

<span class="sd">        where :math:`\log{\lambda_i}` is the log scale parameter (first column of argument ``log_params``)</span>
<span class="sd">        and :math:`\log{\rho_i}` is the log shape parameter (second column of argument ``log_params``).</span>
<span class="sd">        The cumulative hazard for the Weibull survival model of subject :math:`i` at time :math:`t` has the form:</span>

<span class="sd">        .. math::</span>

<span class="sd">            H_i(t) = \left(\frac{t}{\lambda_i}\right)^{\rho_i}</span>

<span class="sd">        The survival function for the Weibull survival model of subject :math:`i` at time :math:`t` has the form:</span>

<span class="sd">        .. math::</span>

<span class="sd">            S_i(t) = 1 - F(t | \lambda_i, \rho_i)</span>

<span class="sd">        where :math:`F(t | \lambda, \rho)` is the cumulative distribution function (CDF) of the Weibull distribution given</span>
<span class="sd">        scale parameter :math:`\lambda` and shape parameter :math:`\rho`.</span>

<span class="sd">        The log likelihood of the Weibull survival model is</span>

<span class="sd">        .. math::</span>

<span class="sd">            ll = \sum_{i: \delta_i = 1} \log h_i(T_i) - \sum_{i = 1}^N H_i(T_i)</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; _ = torch.manual_seed(42)</span>
<span class="sd">        &gt;&gt;&gt; n = 4</span>
<span class="sd">        &gt;&gt;&gt; log_params = torch.randn((n, 2))</span>
<span class="sd">        &gt;&gt;&gt; event = torch.randint(low=0, high=2, size=(n,), dtype=torch.bool)</span>
<span class="sd">        &gt;&gt;&gt; time = torch.randint(low=1, high=100, size=(n,))</span>
<span class="sd">        &gt;&gt;&gt; neg_log_likelihood(log_params, event, time) # Default: mean of log likelihoods across subject</span>
<span class="sd">        tensor(47.5035)</span>
<span class="sd">        &gt;&gt;&gt; neg_log_likelihood(log_params, event, time, reduction = &#39;sum&#39;) # Sum of log likelihoods across subject</span>
<span class="sd">        tensor(190.0141)</span>
<span class="sd">        &gt;&gt;&gt; neg_log_likelihood(torch.randn((n, 1)), event, time)  # Missing shape: exponential decrease</span>
<span class="sd">        tensor(66.7203)</span>

<span class="sd">    References:</span>

<span class="sd">        .. bibliography::</span>
<span class="sd">            :filter: False</span>

<span class="sd">            Carroll2003</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">checks</span><span class="p">:</span>
        <span class="n">_check_inputs</span><span class="p">(</span><span class="n">log_params</span><span class="p">,</span> <span class="n">event</span><span class="p">,</span> <span class="n">time</span><span class="p">)</span>

    <span class="c1"># Negative log likelihood</span>
    <span class="n">nll</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span>
        <span class="n">event</span> <span class="o">*</span> <span class="n">log_hazard</span><span class="p">(</span><span class="n">log_params</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">all_times</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="o">-</span> <span class="n">cumulative_hazard</span><span class="p">(</span><span class="n">log_params</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">all_times</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># Huge values here</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">nll</span><span class="p">)):</span>
        <span class="c1"># Remove any torch.inf values</span>
        <span class="n">nll</span> <span class="o">=</span> <span class="n">nll</span><span class="p">[</span><span class="o">~</span><span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">nll</span><span class="p">)]</span>

    <span class="k">if</span> <span class="n">reduction</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">nll</span><span class="o">.</span><span class="n">nanmean</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">reduction</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">nll</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="p">(</span>
            <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Reduction </span><span class="si">{</span><span class="n">reduction</span><span class="si">}</span><span class="s2"> is not implemented yet, should be one of [&#39;mean&#39;, &#39;sum&#39;].&quot;</span>
            <span class="p">)</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span></div>



<div class="viewcode-block" id="survival_function">
<a class="viewcode-back" href="../../../_autosummary/torchsurv.loss.weibull.html#torchsurv.loss.weibull.survival_function">[docs]</a>
<span class="k">def</span> <span class="nf">survival_function</span><span class="p">(</span>
    <span class="n">log_params</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">time</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">all_times</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Survival function for the Weibull Accelerated Time Failure (AFT) survival model.</span>

<span class="sd">    Args:</span>
<span class="sd">        log_params (torch.Tensor, float):</span>
<span class="sd">            Parameters of the Weibull distribution of shape = (n_samples, 1) or (n_samples, 2).</span>
<span class="sd">            The first column corresponds to the log scale parameter. The second column</span>
<span class="sd">            corresponds to the log shape parameter. If the log shape parameter is missing, it is</span>
<span class="sd">            imputed with 0.</span>
<span class="sd">        time (torch.Tensor, float):</span>
<span class="sd">            Time at which to evaluate the survival function.</span>
<span class="sd">            Should be of length n_samples to evaluate the survival function at observed time-to-event or censoring,</span>
<span class="sd">            or of length one to evaluate the survival function at a new time.</span>
<span class="sd">        all_times (bool):</span>
<span class="sd">            If True, subject-specific survival function is evaluated at all ``time`` (used for evaluation metrics).</span>
<span class="sd">            If False, subject-specific survival function is evaluated at respective ``time``.</span>
<span class="sd">            Defaults is True.</span>
<span class="sd">            Ignored if ``time`` is of length one.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (torch.Tensor, float): Subject-specific survival function evaluated at ``time``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; _ = torch.manual_seed(42)</span>
<span class="sd">        &gt;&gt;&gt; time = torch.randint(low=1, high=100, size=(4,))</span>
<span class="sd">        &gt;&gt;&gt; log_params = torch.randn((4, 2))</span>
<span class="sd">        &gt;&gt;&gt; survival_function(log_params, time, all_times = False)  # Survival at respective time</span>
<span class="sd">        tensor([0.0002, 0.0000, 0.0299, 0.0000])</span>
<span class="sd">        &gt;&gt;&gt; survival_function(log_params, time, all_times = True)  # Default. Survival at all observed time</span>
<span class="sd">        tensor([[1.7941e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00],</span>
<span class="sd">                [2.8610e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00],</span>
<span class="sd">                [4.1870e-01, 3.1040e-02, 2.9881e-02, 6.8224e-02],</span>
<span class="sd">                [9.5576e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00]])</span>
<span class="sd">        &gt;&gt;&gt; survival_function(log_params, time=torch.tensor(10.0))  # Survival at one new time (e.g., 10 years)</span>
<span class="sd">        tensor([1.3709e-06, 5.9605e-08, 3.4954e-01, 1.5438e-05])</span>
<span class="sd">        &gt;&gt;&gt; for t in torch.tensor([100.0, 150.0]): survival_function(log_params, time=t)  # Subject-specific survival at multiple new times</span>
<span class="sd">        tensor([0.0000, 0.0000, 0.0288, 0.0000])</span>
<span class="sd">        tensor([0.0000, 0.0000, 0.0123, 0.0000])</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_scale</span><span class="p">,</span> <span class="n">log_shape</span> <span class="o">=</span> <span class="n">_check_log_shape</span><span class="p">(</span><span class="n">log_params</span><span class="p">)</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">time</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Use one time for each sample</span>
        <span class="n">time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">log_params</span><span class="p">))</span>
    <span class="k">elif</span> <span class="nb">all</span><span class="p">([</span><span class="n">time</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">log_params</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">all_times</span><span class="p">]):</span>
        <span class="c1"># Use all times for each sample</span>
        <span class="n">time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">))</span>  <span class="c1"># expand across rows</span>
        <span class="n">log_scale</span> <span class="o">=</span> <span class="n">log_scale</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
        <span class="p">)</span>  <span class="c1"># expand across columns</span>
        <span class="n">log_shape</span> <span class="o">=</span> <span class="n">log_shape</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
        <span class="p">)</span>  <span class="c1"># expand across columns</span>
    <span class="k">if</span> <span class="n">time</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">!=</span> <span class="n">log_params</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Dimension mismatch: &#39;time&#39; (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">)</span><span class="si">}</span><span class="s2">) does not match the length of &#39;log_params&#39; (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">log_params</span><span class="p">)</span><span class="si">}</span><span class="s2">).&quot;</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">weibull</span><span class="o">.</span><span class="n">Weibull</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_scale</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_shape</span><span class="p">)</span>
    <span class="p">)</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">time</span><span class="p">)</span></div>



<div class="viewcode-block" id="log_hazard">
<a class="viewcode-back" href="../../../_autosummary/torchsurv.loss.weibull.html#torchsurv.loss.weibull.log_hazard">[docs]</a>
<span class="k">def</span> <span class="nf">log_hazard</span><span class="p">(</span>
    <span class="n">log_params</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">time</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">all_times</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Log hazard of the Weibull Accelerated Time Failure (AFT) survival model.</span>

<span class="sd">    Args:</span>
<span class="sd">        log_params (torch.Tensor, float):</span>
<span class="sd">            Parameters of the Weibull distribution of shape = (n_samples, 1) or (n_samples, 2).</span>
<span class="sd">            The first column corresponds to the log scale parameter. The second column</span>
<span class="sd">            corresponds to the log shape parameter. If the log shape parameter is missing, it is</span>
<span class="sd">            imputed with 0.</span>
<span class="sd">        time (torch.Tensor, float):</span>
<span class="sd">            Time at which to evaluate the log hazard.</span>
<span class="sd">            Should be of length n_samples to evaluate the log hazard at observed time-to-event or censoring,</span>
<span class="sd">            or of length one to evaluate the log hazard at a new time.</span>
<span class="sd">        all_times (bool):</span>
<span class="sd">            If True, subject-specific log hazard is evaluated at all ``time`` (used for evaluation metrics).</span>
<span class="sd">            If False, subject-specific log hazard is evaluated at respective ``time``.</span>
<span class="sd">            Defaults is True.</span>
<span class="sd">            Ignored if ``time`` is of length one.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (torch.Tensor, float): Subject-specific log hazard evaluated at ``time``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; _ = torch.manual_seed(42)</span>
<span class="sd">        &gt;&gt;&gt; time = torch.randint(low=1, high=100, size=(4,))</span>
<span class="sd">        &gt;&gt;&gt; log_params = torch.randn((4, 2))</span>
<span class="sd">        &gt;&gt;&gt; log_hazard(log_params, time, all_times = False)  # Log hazard at respective time</span>
<span class="sd">        tensor([ 0.4392, -0.0303, -3.9672,  0.9140])</span>
<span class="sd">        &gt;&gt;&gt; log_hazard(log_params, time, all_times = True)  # Default. Log hazard at all time</span>
<span class="sd">        tensor([[ 0.4392,  1.1174,  1.1227,  0.9913],</span>
<span class="sd">                [ 0.4148, -0.0303, -0.0338,  0.0525],</span>
<span class="sd">                [-2.7225, -3.9575, -3.9672, -3.7279],</span>
<span class="sd">                [ 0.2606,  1.0632,  1.0695,  0.9140]])</span>
<span class="sd">        &gt;&gt;&gt; log_hazard(log_params, time=torch.tensor(10.0))  # Log hazard at one new time (e.g., 10 years)</span>
<span class="sd">        tensor([ 0.5316,  0.3542, -2.8907,  0.3699])</span>
<span class="sd">        &gt;&gt;&gt; for t in torch.tensor([100.0, 150.0]): log_hazard(log_params, time=t)  # Subject-specific log hazard at multiple new times</span>
<span class="sd">        tensor([ 1.1280, -0.0372, -3.9767,  1.0757])</span>
<span class="sd">        tensor([ 1.2330, -0.1062, -4.1680,  1.1999])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">log_scale</span><span class="p">,</span> <span class="n">log_shape</span> <span class="o">=</span> <span class="n">_check_log_shape</span><span class="p">(</span><span class="n">log_params</span><span class="p">)</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">time</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Use fixed time for each sample</span>
        <span class="n">time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">log_params</span><span class="p">))</span>
    <span class="k">elif</span> <span class="nb">all</span><span class="p">([</span><span class="n">time</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">log_params</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">all_times</span><span class="p">]):</span>
        <span class="c1"># Use all times for each sample</span>
        <span class="n">time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">))</span>  <span class="c1"># expand across rows</span>
        <span class="n">log_scale</span> <span class="o">=</span> <span class="n">log_scale</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
        <span class="p">)</span>  <span class="c1"># expand across columns</span>
        <span class="n">log_shape</span> <span class="o">=</span> <span class="n">log_shape</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
        <span class="p">)</span>  <span class="c1"># expand across columns</span>
    <span class="k">if</span> <span class="n">time</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">!=</span> <span class="n">log_params</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Dimension mismatch: &#39;time&#39; (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">)</span><span class="si">}</span><span class="s2">) does not match the length of &#39;log_params&#39; (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">log_params</span><span class="p">)</span><span class="si">}</span><span class="s2">).&quot;</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span>
        <span class="n">log_shape</span>
        <span class="o">-</span> <span class="n">log_scale</span>
        <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">log_shape</span><span class="p">)</span>
        <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="mf">1e-100</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">inf</span><span class="p">))</span> <span class="o">-</span> <span class="n">log_scale</span><span class="p">)</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="cumulative_hazard">
<a class="viewcode-back" href="../../../_autosummary/torchsurv.loss.weibull.html#torchsurv.loss.weibull.cumulative_hazard">[docs]</a>
<span class="k">def</span> <span class="nf">cumulative_hazard</span><span class="p">(</span>
    <span class="n">log_params</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">time</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">all_times</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Cumulative hazard for the Weibull Accelerated Time Failure (AFT) survival model.</span>

<span class="sd">    Args:</span>
<span class="sd">        log_params (torch.Tensor, float):</span>
<span class="sd">            Parameters of the Weibull distribution of shape = (n_samples, 1) or (n_samples, 2).</span>
<span class="sd">            The first column corresponds to the log scale parameter. The second column</span>
<span class="sd">            corresponds to the log shape parameter. If the log shape parameter is missing, it is</span>
<span class="sd">            imputed with 0.</span>
<span class="sd">        time (torch.Tensor, float):</span>
<span class="sd">            Time-to-event or censoring of length n_samples.</span>
<span class="sd">        all_times (bool)</span>
<span class="sd">            If True, subject-specific cumulative hazard is evaluated at all ``time`` (used for evaluation metrics).</span>
<span class="sd">            If False, subject-specific cumulative hazard is evaluated at respective ``time``.</span>
<span class="sd">            Defaults is True.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (torch.Tensor, float): Subject-specific cumulative hazard evaluated at ``time``.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; _ = torch.manual_seed(42)</span>
<span class="sd">        &gt;&gt;&gt; time = torch.randint(low=1, high=100, size=(4,))</span>
<span class="sd">        &gt;&gt;&gt; log_params = torch.randn((4, 2))</span>
<span class="sd">        &gt;&gt;&gt; cumulative_hazard(log_params, time, all_times=False) # Cumulative hazard at respective time</span>
<span class="sd">        tensor([  8.6257, 112.2115,   3.5105, 112.6339])</span>
<span class="sd">        &gt;&gt;&gt; cumulative_hazard(log_params, time, all_times=True) # Default. Cumulative hazard at all time</span>
<span class="sd">        tensor([[  8.6257, 233.0865, 239.2167, 126.2805],</span>
<span class="sd">                [ 12.7698, 112.2115, 114.1484,  74.9134],</span>
<span class="sd">                [  0.8706,   3.4725,   3.5105,   2.6850],</span>
<span class="sd">                [  6.9530, 212.7592, 218.5687, 112.6339]])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_scale</span><span class="p">,</span> <span class="n">log_shape</span> <span class="o">=</span> <span class="n">_check_log_shape</span><span class="p">(</span><span class="n">log_params</span><span class="p">)</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">all_times</span><span class="p">:</span>
        <span class="c1"># Use all times for each sample</span>
        <span class="n">time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">))</span>  <span class="c1"># expand across rows</span>
        <span class="n">log_scale</span> <span class="o">=</span> <span class="n">log_scale</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
        <span class="p">)</span>  <span class="c1"># expand across columns</span>
        <span class="n">log_shape</span> <span class="o">=</span> <span class="n">log_shape</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
        <span class="p">)</span>  <span class="c1"># expand across columns</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_shape</span><span class="p">)</span>
            <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="mf">1e-100</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">inf</span><span class="p">))</span> <span class="o">-</span> <span class="n">log_scale</span><span class="p">)</span>
        <span class="p">),</span>
        <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="nb">max</span><span class="o">=</span><span class="n">TORCH_CLAMP_VALUE</span><span class="p">,</span>
    <span class="p">)</span></div>



<span class="k">def</span> <span class="nf">_check_log_shape</span><span class="p">(</span><span class="n">log_params</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Private function, check if the log shape is missing and impute it with 0</span>
<span class="sd">    if needed.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">log_params</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">log_params</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span>  <span class="c1"># if shape = [n_samples]</span>
            <span class="n">log_params</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span>
            <span class="ow">and</span> <span class="n">log_params</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span>  <span class="c1"># if shape = [n_samples, 1]</span>
        <span class="p">]</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">log_params</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">log_params</span> <span class="o">=</span> <span class="n">log_params</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Missing log shape parameter. Creating zeros placeholder instead.</span>
        <span class="n">log_params</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">log_params</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">log_params</span><span class="p">)))</span>

    <span class="k">return</span> <span class="n">log_params</span>


<span class="k">def</span> <span class="nf">_check_inputs</span><span class="p">(</span><span class="n">log_params</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">event</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">time</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Private function, perform input format checks.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">log_params</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Input &#39;log_params&#39; must be a tensor.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Input &#39;event&#39; must be a tensor.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;``Input &#39;time&#39; must be a tensor.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">log_params</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">event</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Length mismatch: The length of &#39;log_params&#39; must match the length of &#39;event&#39;.&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">event</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Length mismatch: The length of &#39;time&#39; must match the length of &#39;event&#39;.`&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">val</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">time</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;All elements in &#39;time&#39; must be non-negative.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">val</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">event</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;All elements in &#39;event&#39; must be boolean (True/False or 0/1).&quot;</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">doctest</span>

    <span class="c1"># Run doctest</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">doctest</span><span class="o">.</span><span class="n">testmod</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">results</span><span class="o">.</span><span class="n">failed</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;All tests passed.&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Some doctests failed.&quot;</span><span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
       Copyright 2024, Novartis Pharma AG.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>